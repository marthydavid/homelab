additionalPrometheusRulesMap: {}
alertmanager:
  alertmanagerSpec:
    additionalPeers: []
    affinity: {}
    alertmanagerConfigNamespaceSelector: {}
    alertmanagerConfigSelector: {}
    clusterAdvertiseAddress: false
    configMaps: []
    containers: []
    externalUrl: null
    forceEnableClusterMode: false
    image:
      repository: quay.io/prometheus/alertmanager
      sha: ''
      tag: v0.23.0
    initContainers: []
    listenLocal: false
    logFormat: logfmt
    logLevel: info
    nodeSelector: {}
    paused: false
    podAntiAffinity: ''
    podAntiAffinityTopologyKey: kubernetes.io/hostname
    podMetadata: {}
    portName: web
    priorityClassName: ''
    replicas: 1
    resources:
      limits:
        cpu: 300m
        memory: 150Mi
      requests:
        cpu: 50m
        memory: 25Mi
    retention: 120h
    routePrefix: /
    secrets: []
    securityContext:
      fsGroup: 2000
      runAsGroup: 2000
      runAsNonRoot: true
      runAsUser: 1000
    storage: {}
    tolerations: []
    topologySpreadConstraints: []
    useExistingSecret: true
    volumeMounts: []
    volumes: []
    configSecret: alertmanager-rancher-monitoring-alertmanager
  annotations: {}
  apiVersion: v2
  config:
    global:
      resolve_timeout: 5m
    receivers:
      - name: 'null'
    route:
      group_by:
        - job
      group_interval: 5m
      group_wait: 30s
      receiver: 'null'
      repeat_interval: 12h
      routes:
        - match:
            alertname: Watchdog
          receiver: 'null'
    templates:
      - /etc/alertmanager/config/*.tmpl
  enabled: true
  extraSecret:
    annotations: {}
    data: {}
  ingress:
    annotations: {}
    enabled: false
    hosts: []
    labels: {}
    paths: []
    tls: []
  ingressPerReplica:
    annotations: {}
    enabled: false
    hostDomain: ''
    hostPrefix: ''
    labels: {}
    paths: []
    tlsSecretName: ''
    tlsSecretPerReplica:
      enabled: false
      prefix: alertmanager
  podDisruptionBudget:
    enabled: false
    maxUnavailable: ''
    minAvailable: 1
  secret:
    annotations: {}
  service:
    additionalPorts: []
    annotations: {}
    clusterIP: ''
    externalIPs: []
    labels: {}
    loadBalancerIP: ''
    loadBalancerSourceRanges: []
    nodePort: 30903
    port: 9093
    targetPort: 9093
    type: ClusterIP
  serviceAccount:
    annotations: {}
    create: true
    name: ''
  serviceMonitor:
    bearerTokenFile: null
    interval: ''
    metricRelabelings: []
    proxyUrl: ''
    relabelings: []
    scheme: ''
    selfMonitor: true
    tlsConfig: {}
  servicePerReplica:
    annotations: {}
    enabled: false
    loadBalancerSourceRanges: []
    nodePort: 30904
    port: 9093
    targetPort: 9093
    type: ClusterIP
  templateFiles:
    rancher_defaults.tmpl: >-
      {{- define "slack.rancher.text" -}}

      {{ template "rancher.text_multiple" . }}

      {{- end -}}


      {{- define "rancher.text_multiple" -}}

      *[GROUP - Details]*

      One or more alarms in this group have triggered a notification.


      {{- if gt (len .GroupLabels.Values) 0 }}

      *Group Labels:*
        {{- range .GroupLabels.SortedPairs }}
        • *{{ .Name }}:* `{{ .Value }}`
        {{- end }}
      {{- end }}

      {{- if .ExternalURL }}

      *Link to AlertManager:* {{ .ExternalURL }}

      {{- end }}


      {{- range .Alerts }}

      {{ template "rancher.text_single" . }}

      {{- end }}

      {{- end -}}


      {{- define "rancher.text_single" -}}

      {{- if .Labels.alertname }}

      *[ALERT - {{ .Labels.alertname }}]*

      {{- else }}

      *[ALERT]*

      {{- end }}

      {{- if .Labels.severity }}

      *Severity:* `{{ .Labels.severity }}`

      {{- end }}

      {{- if .Labels.cluster }}

      *Cluster:*  {{ .Labels.cluster }}

      {{- end }}

      {{- if .Annotations.summary }}

      *Summary:* {{ .Annotations.summary }}

      {{- end }}

      {{- if .Annotations.message }}

      *Message:* {{ .Annotations.message }}

      {{- end }}

      {{- if .Annotations.description }}

      *Description:* {{ .Annotations.description }}

      {{- end }}

      {{- if .Annotations.runbook_url }}

      *Runbook URL:* <{{ .Annotations.runbook_url }}|:spiral_note_pad:>

      {{- end }}

      {{- with .Labels }}

      {{- with .Remove (stringSlice "alertname" "severity" "cluster") }}

      {{- if gt (len .) 0 }}

      *Additional Labels:*
        {{- range .SortedPairs }}
        • *{{ .Name }}:* `{{ .Value }}`
        {{- end }}
      {{- end }}

      {{- end }}

      {{- end }}

      {{- with .Annotations }}

      {{- with .Remove (stringSlice "summary" "message" "description"
      "runbook_url") }}

      {{- if gt (len .) 0 }}

      *Additional Annotations:*
        {{- range .SortedPairs }}
        • *{{ .Name }}:* `{{ .Value }}`
        {{- end }}
      {{- end }}

      {{- end }}

      {{- end }}

      {{- end -}}
  tplConfig: false
commonLabels: {}
coreDns:
  enabled: true
  service:
    port: 9153
    targetPort: 9153
  serviceMonitor:
    interval: ''
    metricRelabelings: []
    proxyUrl: ''
    relabelings: []
defaultRules:
  additionalRuleLabels: {}
  annotations: {}
  appNamespacesTarget: .*
  create: true
  labels: {}
  rules:
    alertmanager: true
    etcd: true
    general: true
    k8s: true
    kubeApiserver: true
    kubeApiserverAvailability: true
    kubeApiserverError: true
    kubeApiserverSlos: true
    kubePrometheusGeneral: true
    kubePrometheusNodeAlerting: true
    kubePrometheusNodeRecording: true
    kubeScheduler: true
    kubeStateMetrics: true
    kubelet: true
    kubernetesAbsent: true
    kubernetesApps: true
    kubernetesResources: true
    kubernetesStorage: true
    kubernetesSystem: true
    network: true
    node: true
    prometheus: true
    prometheusOperator: true
    time: true
  runbookUrl: >-
    https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#
fullnameOverride: ''
global:
  cattle:
    systemDefaultRegistry: ''
    windows:
      enabled: false
  imagePullSecrets: []
  kubectl:
    pullPolicy: IfNotPresent
    repository: rancher/kubectl
    tag: v1.20.2
  rbac:
    create: true
    pspAnnotations: {}
    pspEnabled: true
    userRoles:
      aggregateToDefaultRoles: true
      create: true
grafana:
  additionalDataSources: []
  adminPassword: prom-operator
  defaultDashboards:
    cleanupOnUninstall: false
    namespace: cattle-dashboards
    useExistingNamespace: false
  defaultDashboardsEnabled: true
  defaultDashboardsTimezone: utc
  deploymentStrategy:
    type: Recreate
  enabled: true
  extraConfigmapMounts: []
  extraContainerVolumes:
    - emptyDir: {}
      name: nginx-home
    - configMap:
        items:
          - key: nginx.conf
            mode: 438
            path: nginx.conf
        name: grafana-nginx-proxy-config
      name: grafana-nginx
  extraContainers: |
    - name: grafana-proxy
      args:
      - nginx
      - -g
      - daemon off;
      - -c
      - /nginx/nginx.conf
      image: "{{ template "system_default_registry" . }}{{ .Values.proxy.image.repository }}:{{ .Values.proxy.image.tag }}"
      ports:
      - containerPort: 8080
        name: nginx-http
        protocol: TCP
      volumeMounts:
      - mountPath: /nginx
        name: grafana-nginx
      - mountPath: /var/cache/nginx
        name: nginx-home
      securityContext:
        runAsUser: 101
        runAsGroup: 101
  forceDeployDashboards: false
  forceDeployDatasources: false
  grafana.ini:
    auth:
      disable_login_form: false
    auth.anonymous:
      enabled: true
      org_role: Viewer
    auth.basic:
      enabled: false
    dashboards:
      default_home_dashboard_path: /tmp/dashboards/rancher-default-home.json
    security:
      allow_embedding: true
    users:
      auto_assign_org_role: Viewer
  ingress:
    annotations: {}
    enabled: false
    hosts: []
    labels: {}
    path: /
    tls: []
  namespaceOverride: ''
  proxy:
    image:
      repository: rancher/mirrored-library-nginx
      tag: 1.21.1-alpine
  resources:
    limits:
      cpu: 200m
      memory: 200Mi
    requests:
      cpu: 100m
      memory: 100Mi
  service:
    nodePort: 30950
    port: 80
    portName: nginx-http
    targetPort: 8080
    type: ClusterIP
  serviceMonitor:
    interval: ''
    metricRelabelings: []
    path: /metrics
    relabelings: []
    selfMonitor: true
  sidecar:
    dashboards:
      annotations: {}
      enabled: true
      label: grafana_dashboard
      multicluster:
        etcd:
          enabled: false
        global:
          enabled: false
      provider:
        allowUiUpdates: false
      searchNamespace: cattle-dashboards
    datasources:
      annotations: {}
      createPrometheusReplicasDatasources: false
      defaultDatasourceEnabled: true
      enabled: true
      label: grafana_datasource
  testFramework:
    enabled: false
hardenedKubelet:
  enabled: false
hardenedNodeExporter:
  enabled: false
ingressNginx:
  enabled: true
  namespace: ingress-nginx
  service:
    port: 9913
    targetPort: 10254
  serviceMonitor:
    interval: ''
    metricRelabelings: []
    proxyUrl: ''
    relabelings: []
k3sServer:
  clients:
    https:
      enabled: true
      insecureSkipVerify: true
      useServiceAccountCredentials: true
    port: 10013
    rbac:
      additionalRules:
        - nonResourceURLs:
            - /metrics/cadvisor
          verbs:
            - get
        - apiGroups:
            - ''
          resources:
            - nodes/metrics
          verbs:
            - get
    tolerations:
      - effect: NoExecute
        operator: Exists
      - effect: NoSchedule
        operator: Exists
    useLocalhost: true
  component: k3s-server
  enabled: true
  metricsPort: 10250
  serviceMonitor:
    endpoints:
      - honorLabels: true
        port: metrics
        relabelings:
          - sourceLabels:
              - __metrics_path__
            targetLabel: metrics_path
      - honorLabels: true
        path: /metrics/cadvisor
        port: metrics
        relabelings:
          - sourceLabels:
              - __metrics_path__
            targetLabel: metrics_path
      - honorLabels: true
        path: /metrics/probes
        port: metrics
        relabelings:
          - sourceLabels:
              - __metrics_path__
            targetLabel: metrics_path
kube-state-metrics:
  namespaceOverride: ''
  podSecurityPolicy:
    enabled: true
  rbac:
    create: true
  resources:
    limits:
      cpu: 100m
      memory: 200Mi
    requests:
      cpu: 100m
      memory: 130Mi
nameOverride: rancher-monitoring
namespaceOverride: cattle-monitoring-system
nodeExporter:
  enabled: true
prometheus:
  enabled: true
  ingress:
    enabled: false
  ingressPerReplica:
    enabled: false
  podDisruptionBudget:
    enabled: false

  prometheusSpec:
    containers: |
      - name: prometheus-proxy
        args:
        - nginx
        - -g
        - daemon off;
        - -c
        - /nginx/nginx.conf
        image: "{{ template "system_default_registry" . }}{{ .Values.prometheus.prometheusSpec.proxy.image.repository }}:{{ .Values.prometheus.prometheusSpec.proxy.image.tag }}"
        ports:
        - containerPort: 8081
          name: nginx-http
          protocol: TCP
        volumeMounts:
        - mountPath: /nginx
          name: prometheus-nginx
        - mountPath: /var/cache/nginx
          name: nginx-home
        securityContext:
          runAsUser: 101
          runAsGroup: 101
    disableCompaction: false
    enableAdminAPI: true
    enableFeatures: []
    evaluationInterval: 1m
    externalUrl: ''
    image:
      repository: quay.io/prometheus/prometheus
      sha: ''
      tag: v2.34.0
    listenLocal: false
    logFormat: logfmt
    logLevel: info
    paused: false
    podAntiAffinity: ''
    podAntiAffinityTopologyKey: kubernetes.io/hostname
    podMetadata: {}
    podMonitorNamespaceSelector: {}
    podMonitorSelector: {}
    podMonitorSelectorNilUsesHelmValues: false
    portName: nginx-http
    priorityClassName: ''
    probeNamespaceSelector: {}
    probeSelector: {}
    probeSelectorNilUsesHelmValues: true
    prometheusExternalLabelName: ''
    prometheusExternalLabelNameClear: false
    prometheusRulesExcludedFromEnforce: []
    proxy:
      image:
        repository: rancher/mirrored-library-nginx
        tag: 1.21.1-alpine
    query: {}
    queryLogFile: false
    remoteRead: []
    remoteWrite: []
    remoteWriteDashboards: false
    replicaExternalLabelName: ''
    replicaExternalLabelNameClear: false
    replicas: 1
    resources:
      limits:
        cpu: 500m
        memory: 500Mi
      requests:
        cpu: 100m
        memory: 100Mi
    retention: 100d
    retentionSize: 45GiB
    routePrefix: /
    ruleNamespaceSelector: {}
    ruleSelector: {}
    ruleSelectorNilUsesHelmValues: false
    scrapeInterval: 1m
    scrapeTimeout: ''
    secrets: []
    securityContext:
      fsGroup: 2000
      runAsGroup: 2000
      runAsNonRoot: true
      runAsUser: 1000
    serviceMonitorNamespaceSelector: {}
    serviceMonitorSelector: {}
    serviceMonitorSelectorNilUsesHelmValues: false
    shards: 1
    storageSpec:
      volumeClaimTemplate:
        spec:
          accessModes:
            - ReadWriteOnce
          resources:
            requests:
              storage: 50Gi
          volumeMode: Filesystem
    thanos: {}
    tolerations: []
    topologySpreadConstraints: []
    volumeMounts: []
    volumes:
      - emptyDir: {}
        name: nginx-home
      - configMap:
          defaultMode: 438
          name: prometheus-nginx-proxy-config
        name: prometheus-nginx
    walCompression: false
    web: {}
  service:
    annotations: {}
    clusterIP: ''
    externalIPs: []
    labels: {}
    loadBalancerIP: ''
    loadBalancerSourceRanges: []
    nodePort: 30090
    port: 9090
    sessionAffinity: ''
    targetPort: 8081
    type: ClusterIP
  serviceAccount:
    annotations: {}
    create: true
    name: ''
  serviceMonitor:
    bearerTokenFile: null
    interval: ''
    metricRelabelings: []
    relabelings: []
    scheme: ''
    selfMonitor: true
    tlsConfig: {}
  servicePerReplica:
    annotations: {}
    enabled: false
    loadBalancerSourceRanges: []
    nodePort: 30091
    port: 9090
    targetPort: 9090
    type: ClusterIP
  thanosIngress:
    annotations: {}
    enabled: false
    hosts: []
    labels: {}
    nodePort: 30901
    paths: []
    servicePort: 10901
    tls: []
  thanosService:
    annotations: {}
    clusterIP: None
    enabled: false
    httpNodePort: 30902
    httpPort: 10902
    httpPortName: http
    labels: {}
    nodePort: 30901
    port: 10901
    portName: grpc
    targetHttpPort: http
    targetPort: grpc
    type: ClusterIP
  thanosServiceExternal:
    annotations: {}
    enabled: false
    httpNodePort: 30902
    httpPort: 10902
    httpPortName: http
    labels: {}
    loadBalancerIP: ''
    loadBalancerSourceRanges: []
    nodePort: 30901
    port: 10901
    portName: grpc
    targetHttpPort: http
    targetPort: grpc
    type: LoadBalancer
  thanosServiceMonitor:
    bearerTokenFile: null
    enabled: false
    interval: ''
    metricRelabelings: []
    relabelings: []
    scheme: ''
    tlsConfig: {}
prometheus-adapter:
  enabled: true
  prometheus:
    port: 9090
    url: http://rancher-monitoring-prometheus.cattle-monitoring-system.svc
  psp:
    create: true
prometheus-node-exporter:
  extraArgs:
    - >-
      --collector.filesystem.ignored-mount-points=^/(dev|proc|sys|var/lib/docker/.+|var/lib/kubelet/.+)($|/)
    - >-
      --collector.filesystem.ignored-fs-types=^(autofs|binfmt_misc|bpf|cgroup2?|configfs|debugfs|devpts|devtmpfs|fusectl|hugetlbfs|iso9660|mqueue|nsfs|overlay|proc|procfs|pstore|rpc_pipefs|securityfs|selinuxfs|squashfs|sysfs|tracefs)$
  namespaceOverride: ''
  podLabels:
    jobLabel: node-exporter
  resources:
    limits:
      cpu: 200m
      memory: 50Mi
    requests:
      cpu: 100m
      memory: 30Mi
  service:
    port: 9796
    targetPort: 9796
prometheusOperator:
  admissionWebhooks:
    caBundle: ''
    certManager:
      enabled: false
    enabled: true
    failurePolicy: Fail
    patch:
      affinity: {}
      enabled: true
      image:
        pullPolicy: IfNotPresent
        repository: rancher/mirrored-ingress-nginx-kube-webhook-certgen
        sha: ''
        tag: v1.0
      nodeSelector: {}
      podAnnotations: {}
      priorityClassName: ''
      resources: {}
      securityContext:
        runAsGroup: 2000
        runAsNonRoot: true
        runAsUser: 2000
      tolerations: []
  affinity: {}
  alertmanagerInstanceNamespaces: []
  configReloaderCpu: 100m
  configReloaderMemory: 50Mi
  denyNamespaces: []
  dnsConfig: {}
  enabled: true
  hostNetwork: false
  image:
    pullPolicy: IfNotPresent
    repository: quay.io/prometheus-operator/prometheus-operator
    sha: ''
    tag: v0.55.0
  kubeletService:
    enabled: true
    namespace: kube-system
  namespaces: {}
  nodeSelector: {}
  podAnnotations: {}
  podLabels: {}
  prometheusConfigReloaderImage:
    repository: quay.io/prometheus-operator/prometheus-config-reloader
    sha: ''
    tag: v0.55.0
  prometheusInstanceNamespaces: []
  resources:
    limits:
      cpu: 200m
      memory: 500Mi
    requests:
      cpu: 100m
      memory: 100Mi
  secretFieldSelector: ''
  securityContext:
    fsGroup: 65534
    runAsGroup: 65534
    runAsNonRoot: true
    runAsUser: 65534
  service:
    additionalPorts: []
    annotations: {}
    clusterIP: ''
    externalIPs: []
    labels: {}
    loadBalancerIP: ''
    loadBalancerSourceRanges: []
    nodePort: 30080
    nodePortTls: 30443
    type: ClusterIP
  serviceAccount:
    create: true
    name: ''
  serviceMonitor:
    interval: ''
    metricRelabelings: []
    relabelings: []
    scrapeTimeout: ''
    selfMonitor: true
  thanosImage:
    repository: quay.io/thanos/thanos
    sha: ''
    tag: v0.25.1
  thanosRulerInstanceNamespaces: []
  tls:
    enabled: true
    internalPort: 8443
    tlsMinVersion: VersionTLS13
  tolerations: []

k3sControllerManager:
  enabled: true
k3sProxy:
  enabled: true
k3sScheduler:
  enabled: true
rke2Scheduler:
  enabled: false
rke2ControllerManager:
  enabled: false
rke2Etcd:
  enabled: false
rke2IngressNginx:
  enabled: false
rke2Proxy:
  enabled: false
rkeControllerManager:
  enabled: false
rkeEtcd:
  enabled: false
rkeIngressNginx:
  enabled: false
rkeProxy:
  enabled: false
rkeScheduler:
  enabled: false
kubeDns:
  enabled: false
kubeEtcd:
  enabled: false
kubeProxy:
  enabled: false
kubeScheduler:
  enabled: false
kubeStateMetrics:
  enabled: true
kubelet:
  enabled: true
kubeApiServer:
  enabled: true
kubeControllerManager:
  enabled: false
kubeAdmControllerManager:
  enabled: false
kubeAdmEtcd:
  enabled: false
kubeAdmProxy:
  enabled: false
kubeAdmScheduler:
  enabled: false